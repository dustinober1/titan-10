---
phase: 01-foundation-data-ingestion
plan: 05
type: execute
wave: 3
depends_on: ["01-02", "01-04"]
files_modified:
  - "src/ingestor/resilience.py"
  - "src/ingestor/scheduler.py"
autonomous: true
user_setup: []

must_haves:
  truths:
    - "System implements exponential backoff with jitter for all external API calls"
    - "Circuit breakers prevent cascade failures when exchanges are down"
    - "Per-symbol error isolation prevents one bad symbol from stopping others"
    - "Retry logic respects exchange rate limits and backoff headers"
    - "System autonomously recovers from transient failures without human intervention"
  artifacts:
    - path: "src/ingestor/resilience.py"
      provides: "Circuit breakers, exponential backoff, and error tracking"
      exports: ["CircuitBreaker", "RetryTracker", "with_resilience"]
    - path: "src/ingestor/scheduler.py"
      provides: "Updated scheduler with resilience integration"
      exports: ["IngestionScheduler"]
  key_links:
    - from: "src/ingestor/resilience.py"
      to: "Tenacity retry decorators"
      via: "@retry with exponential backoff"
      pattern: "@retry\\("
    - from: "src/ingestor/resilience.py"
      to: "Exchange fetch operations"
      via: "CircuitBreaker wrapper around fetch_ohlcv"
      pattern: "CircuitBreaker.*call\\(.*fetch_ohlcv"
    - from: "src/ingestor/scheduler.py"
      to: "src/ingestor/resilience.py"
      via: "Resilience decorators on scheduled jobs"
      pattern: "with_resilience|CircuitBreaker"
    - from: "src/ingestor/fetcher.py"
      to: "src/ingestor/resilience.py"
      via: "ExchangeResilienceManager.fetch_with_resilience wrapping all ExchangeWrapper.fetch_ohlcv calls"
      pattern: "fetch_with_resilience.*fetch_ohlcv"
---

<objective>
Implement autonomous error handling with exponential backoff, circuit breakers, and per-symbol error isolation.

Purpose: Ensure system survives exchange API failures, rate limits, and network issues without crashing. Circuit breakers prevent cascade failures, while exponential backoff respects rate limits and reduces retry storms.
Output: Resilient data ingestion that autonomously recovers from failures and degrades gracefully.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-data-ingestion/01-RESEARCH.md
@.planning/REQUIREMENTS.md
@.planning/phases/01-foundation-data-ingestion/01-02-PLAN.md
@.planning/phases/01-foundation-data-ingestion/01-04-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement CircuitBreaker for exchange failure isolation</name>
  <files>
    src/ingestor/resilience.py
  </files>
  <action>
    Create CircuitBreaker class following resilience patterns from research:

    1. src/ingestor/resilience.py:
       - Import asyncio, logging, time
       - Define CircuitBreaker class with __init__(failure_threshold: int=5, recovery_timeout: int=60)
       - In __init__: store threshold and timeout, initialize failure_count=0, last_failure_time=None, state='closed' (states: closed, open, half_open)
       - Define async call method: func, *args, **kwargs
       - In call:
         * Check state: if open and time < recovery_timeout, raise CircuitBreakerOpenError
         * Try: result = await func(*args, **kwargs)
         * On success: reset failure_count to 0, set state to 'closed', return result
         * On failure: increment failure_count, update last_failure_time, if failure_count >= threshold: set state to 'open', log warning
         * Re-raise the exception
       - Define _can_attempt method: check if enough time passed to try recovery
       - Define get_state method: return current state and failure count

    Reference: Pitfall 1 (rate limit IP bans), AUTO-04 requirement (retry logic), AUTO-05 requirement (checkpoints)
  </action>
  <verify>
    Run: python -c "from src.ingestor.resilience import CircuitBreaker; print(CircuitBreaker.__doc__)"
    Check: CircuitBreaker has call method and state management
  </verify>
  <done>
    CircuitBreaker implements open/closed/half-open states, tracks failures, prevents calls when open
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement exponential backoff with jitter</name>
  <files>
    src/ingestor/resilience.py
  </files>
  <action>
    Add enhanced retry logic with jitter to src/ingestor/resilience.py:

    1. Add to src/ingestor/resilience.py:
       - Import random (for jitter)
       - Define RetryTracker class with __init__(max_retries: int=5, base_delay: int=1, max_delay: int=60)
       - In __init__: store retry parameters, initialize attempt_count=0
       - Define async execute_with_retry method: func, *args, **kwargs
       - In execute_with_retry:
         * Enter while attempt_count < max_retries loop
         * Try: result = await func(*args, **kwargs), return result
         * On exception:
           - Increment attempt_count
           - If attempt_count >= max_retries: raise last exception
           - Calculate delay: min(base_delay * (2 ** attempt_count), max_delay)
           - Add jitter: delay = delay + random.uniform(0, 1) (prevents thundering herd)
           - Log retry attempt with delay
           - Await asyncio.sleep(delay)
       - Define get_attempt_count method: return current attempt count
       - Define reset method: reset attempt_count to 0

    Reference: Tenacity retry patterns, Pitfall 1 (exponential backoff), Anti-Patterns section (custom retry loops)
  </action>
  <verify>
    Run: python -c "from src.ingestor.resilience import RetryTracker; print(RetryTracker.__doc__)"
    Check: RetryTracker has execute_with_retry method with exponential backoff logic
  </verify>
  <done>
    RetryTracker implements exponential backoff with jitter, prevents thundering herd on retries
  </done>
</task>

<task type="auto">
  <name>Task 3: Create resilience wrapper for exchange operations</name>
  <files>
    src/ingestor/resilience.py
  </files>
  <action>
    Create high-level resilience wrapper combining circuit breaker and retry logic:

    1. Add to src/ingestor/resilience.py:
       - Define with_resilience decorator factory accepting: max_retries (int=5), circuit_breaker_threshold (int=5)
       - In with_resilience:
         * Return decorator function that wraps async functions
         * In wrapper: create CircuitBreaker and RetryTracker instances
         * Define inner resilient_call function:
           - Check circuit breaker state, raise CircuitBreakerOpenError if open
           - Use RetryTracker.execute_with_retry to call original function
           - On CircuitBreakerOpenError: log and re-raise
           - On final failure: log error, let circuit breaker record failure
         * Return resilient_call
       - Define ExchangeResilienceManager class with __init__(exchange_id: str)
       - In __init__: create CircuitBreaker per exchange, create RetryTracker
       - Define async fetch_with_resilience method: exchange_wrapper, symbol
       - In fetch_with_resilience:
         * Use circuit breaker to wrap exchange.fetch_ohlcv call
         * On success: reset tracker, return data
         * On failure: let circuit breaker track, raise after retries exhausted
       - Define get_health_status method: return circuit breaker state and retry stats

    Reference: AUTO-01 requirement (auto-recover from API disconnections), AUTO-03 requirement (graceful degradation)
  </action>
  <verify>
    Run: python -c "from src.ingestor.resilience import with_resilience, ExchangeResilienceManager; print(with_resilience.__doc__)"
    Check: Decorator and manager class exist with proper integration
  </verify>
  <done>
    with_resilience decorator combines circuit breaker and retry logic, ExchangeResilienceManager per-exchange isolation
  </done>
</task>

<task type="auto">
  <name>Task 4: Integrate resilience into scheduler and fetcher</name>
  <files>
    src/ingestor/scheduler.py
    src/ingestor/fetcher.py
  </files>
  <action>
    Update scheduler and fetcher to use resilience components:

    1. Update src/ingestor/scheduler.py:
       - Import ExchangeResilienceManager from src.ingestor.resilience
       - In IngestionScheduler.__init__: create dict of ExchangeResilienceManager instances (one per exchange)
       - In fetch_realtime_data method:
         * Log resilience status before fetching
         * Use ExchangeResilienceManager.fetch_with_resilience for all exchange calls
         * Log per-exchange health status after fetching
         * Continue with available exchanges (graceful degradation)
       - Add get_system_health method: return dict of all exchange circuit breaker states

    2. Update src/ingestor/fetcher.py:
       - Import ExchangeResilienceManager from src.ingestor.resilience
       - In fetch_multi_exchange_ohlcv:
         * Create ExchangeResilienceManager per exchange
         * CRITICAL: Wrap ALL ExchangeWrapper.fetch_ohlcv calls with ExchangeResilienceManager.fetch_with_resilience
         * Ensure no direct calls to exchange.fetch_ohlcv remain unwrapped
         * Handle CircuitBreakerOpenError gracefully (log, skip exchange)
         * Log aggregate health stats after all fetches complete

    Reference: AUTO-01 requirement (auto-recover from disconnections), AUTO-02 requirement (auto-recover from database loss)
  </action>
  <verify>
    Run: python -c "from src.ingestor.scheduler import IngestionScheduler; print(hasattr(IngestionScheduler, 'get_system_health'))"
    Check: IngestionScheduler has health monitoring method
    Run: python -c "from src.ingestor.fetcher import fetch_multi_exchange_ohlcv; import inspect; source = inspect.getsource(fetch_multi_exchange_ohlcv); print('fetch_with_resilience' in source and 'exchange.fetch_ohlcv' not in source)"
    Check: fetch_multi_exchange_ohlcv uses fetch_with_resilience for all exchange fetch calls (no direct calls)
  </verify>
  <done>
    Scheduler uses ExchangeResilienceManager for all exchange calls, fetcher wraps all fetch_ohlcv calls with fetch_with_resilience
  </done>
</task>

<task type="auto">
  <name>Task 5: Add per-symbol error isolation and tracking</name>
  <files>
    src/ingestor/resilience.py
  </files>
  <action>
    Add symbol-level error tracking to prevent cascading failures:

    1. Add to src/ingestor/resilience.py:
       - Define SymbolErrorTracker class with __init__(max_failures: int=10)
       - In __init__: create dict symbol_failures = {}, store max_failures threshold
       - Define record_failure method: symbol, error
       - In record_failure:
         * Initialize failure count if symbol not in dict
         * Increment failure count for symbol
         * Log warning if failure count >= max_failures
         * Return True if symbol should be skipped (too many failures)
       - Define record_success method: symbol
       - In record_success:
         * Reset failure count for symbol to 0
         * Log recovery message if symbol was previously failing
       - Define should_skip_symbol method: symbol
       - In should_skip_symbol:
         * Return True if failure count >= max_failures
         * Return False otherwise
       - Define get_failing_symbols method: return list of symbols exceeding threshold
       - Define get_all_status method: return dict of all symbols and failure counts

    Reference: AUTO-03 requirement (continue operating with partial failures), AUTO-05 requirement (checkpoints)
  </action>
  <verify>
    Run: python -c "from src.ingestor.resilience import SymbolErrorTracker; print(SymbolErrorTracker.__doc__)"
    Check: SymbolErrorTracker tracks failures per symbol
  </verify>
  <done>
    SymbolErrorTracker isolates errors per symbol, prevents one bad symbol from affecting others
  </done>
</task>

</tasks>

<verification>
## Automated Verification

1. **Module Import**: Run `python -c "from src.ingestor.resilience import CircuitBreaker, RetryTracker, with_resilience, ExchangeResilienceManager, SymbolErrorTracker"` to confirm all modules load
2. **Circuit Breaker Logic**: Run `python -c "from src.ingestor.resilience import CircuitBreaker; import inspect; print('state' in inspect.getsource(CircuitBreaker))"` to verify state management
3. **Exponential Backoff**: Run `python -c "from src.ingestor.resilience import RetryTracker; import inspect; print('2 **' in inspect.getsource(RetryTracker.execute_with_retry))"` to verify backoff calculation
4. **Scheduler Integration**: Run `python -c "from src.ingestor.scheduler import IngestionScheduler; import inspect; print('ExchangeResilienceManager' in inspect.getsource(IngestionScheduler))"` to confirm resilience integration
5. **Fetcher Resilience Wrapper**: Run `python -c "from src.ingestor.fetcher import fetch_multi_exchange_ohlcv; import inspect; source = inspect.getsource(fetch_multi_exchange_ohlcv); print('fetch_with_resilience' in source and 'exchange.fetch_ohlcv' not in source)"` to verify all exchange calls are wrapped

## Success Criteria
- [ ] CircuitBreaker implements open/closed/half-open states
- [ ] RetryTracker uses exponential backoff: min(base_delay * (2 ** attempt), max_delay)
- [ ] Jitter is added to backoff: delay + random.uniform(0, 1)
- [ ] ExchangeResilienceManager combines circuit breaker and retry logic
- [ ] Scheduler uses resilience managers for all exchange calls
- [ ] fetch_multi_exchange_ohlcv wraps ALL ExchangeWrapper.fetch_ohlcv calls with fetch_with_resilience
- [ ] SymbolErrorTracker isolates errors per symbol
- [ ] System logs health status and recovery events
</verification>

<success_criteria>
1. CircuitBreaker prevents calls to failing exchanges (open state) with timeout recovery
2. RetryTracker implements exponential backoff with jitter (prevents thundering herd)
3. ExchangeResilienceManager combines both patterns for per-exchange resilience
4. Scheduler logs health status and continues with available exchanges
5. fetch_multi_exchange_ohlcv wraps all fetch_ohlcv calls with fetch_with_resilience (verified via code inspection)
6. SymbolErrorTracker prevents one bad symbol from stopping entire pipeline
7. All exchange API calls use resilience wrappers (no direct calls)
8. System autonomously recovers from transient failures without intervention
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-data-ingestion/01-05-SUMMARY.md` with:
- Resilience implementation status (circuit breakers, retry logic, error tracking)
- Per-exchange and per-symbol isolation details
- Integration with scheduler and fetcher
- Verification that all fetch_ohlcv calls are wrapped with fetch_with_resilience
- Testing results (if applicable)
- Phase 01 completion status and next steps
</output>
